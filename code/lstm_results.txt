ALL TRAINED ON 30 EPOCHS 256 Batch size and 0.001 learning rate
with Adam optimizer


./logs/max_tokens=125_hidden_state_size=64_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.94448
F1 on Train Set: 0.9449381148841638
Accuracy on Test Set: 0.8024
F1 on Test Set: 0.8074424406215893

./logs/max_tokens=250_hidden_state_size=64_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.955
F1 on Train Set: 0.9548718360142806
Accuracy on Test Set: 0.83328
F1 on Test Set: 0.831536969174391

./logs/max_tokens=500_hidden_state_size=64_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.96372
F1 on Train Set: 0.9638256291628445
Accuracy on Test Set: 0.8471466666666667
F1 on Test Set: 0.8495064062171812

./logs/max_tokens=1000_hidden_state_size=64_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.94456
F1 on Train Set: 0.9453340695748206
Accuracy on Test Set: 0.8334933333333333
F1 on Test Set: 0.8316618138682196

./logs/max_tokens=2000_hidden_state_size=64_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.95248
F1 on Train Set: 0.9525179856115107
Accuracy on Test Set: 0.82352
F1 on Test Set: 0.8205044751830757

./logs/max_tokens=125_hidden_state_size=128_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.93188
F1 on Train Set: 0.931399798590131
Accuracy on Test Set: 0.80352
F1 on Test Set: 0.8071204188481675

./logs/max_tokens=250_hidden_state_size=128_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.94072
F1 on Train Set: 0.9406059634498236
Accuracy on Test Set: 0.8245866666666667
F1 on Test Set: 0.8237689546160853

./logs/max_tokens=500_hidden_state_size=128_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.95272
F1 on Train Set: 0.9528708133971292
Accuracy on Test Set: 0.8296533333333334
F1 on Test Set: 0.835445646573931

./logs/max_tokens=1000_hidden_state_size=128_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.94756
F1 on Train Set: 0.9469767441860465
Accuracy on Test Set: 0.8466666666666667
F1 on Test Set: 0.8450385382417938

./logs/max_tokens=2000_hidden_state_size=128_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.95168
F1 on Train Set: 0.9519490851233094
Accuracy on Test Set: 0.8441066666666667
F1 on Test Set: 0.8479425687977943

./logs/max_tokens=125_hidden_state_size=256_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.94888
F1 on Train Set: 0.9488472622478386
Accuracy on Test Set: 0.79952
F1 on Test Set: 0.8095069173465768

./logs/max_tokens=250_hidden_state_size=256_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.95324
F1 on Train Set: 0.9526778124114481
Accuracy on Test Set: 0.82944
F1 on Test Set: 0.8271725032425422

./logs/max_tokens=500_hidden_state_size=256_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.95688
F1 on Train Set: 0.9568005129438166
Accuracy on Test Set: 0.8306133333333333
F1 on Test Set: 0.8399677516879975

./logs/max_tokens=1000_hidden_state_size=256_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.94272
F1 on Train Set: 0.9423788829872847
Accuracy on Test Set: 0.8390933333333334
F1 on Test Set: 0.8452106100251399

./logs/max_tokens=2000_hidden_state_size=256_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.96356
F1 on Train Set: 0.9638161814354371
Accuracy on Test Set: 0.84944
F1 on Test Set: 0.8534800435978618

./logs/max_tokens=125_hidden_state_size=512_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.91356
F1 on Train Set: 0.912534909135063
Accuracy on Test Set: 0.80064
F1 on Test Set: 0.7970463676837877

./logs/max_tokens=250_hidden_state_size=512_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.95168
F1 on Train Set: 0.9517494807477233
Accuracy on Test Set: 0.8354133333333333
F1 on Test Set: 0.8357637040979243

./logs/max_tokens=500_hidden_state_size=512_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.94744
F1 on Train Set: 0.9479397781299524
Accuracy on Test Set: 0.8472
F1 on Test Set: 0.8464712502009539

./logs/max_tokens=1000_hidden_state_size=512_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.915
F1 on Train Set: 0.9179124657163827
Accuracy on Test Set: 0.83168
F1 on Test Set: 0.8336320506062203

./logs/max_tokens=2000_hidden_state_size=512_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.94912
F1 on Train Set: 0.9500784929356358
Accuracy on Test Set: 0.85152
F1 on Test Set: 0.8545910372923848

./logs/max_tokens=125_hidden_state_size=1024_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.5
F1 on Train Set: 0.6666666666666666
Accuracy on Test Set: 0.5
F1 on Test Set: 0.6666666666666666

./logs/max_tokens=250_hidden_state_size=1024_embedding_size=50_no_stem_sr.log results
Accuracy on Train Set: 0.59844
F1 on Train Set: 0.555146895909957
Accuracy on Test Set: 0.59152
F1 on Test Set: 0.5497619187584505
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 5.93 GiB total capacity; 3.49 GiB already allocated; 24.44 MiB free; 4.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=500_hidden_state_size=1024_embedding_size=50_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 774.00 MiB (GPU 0; 5.93 GiB total capacity; 3.23 GiB already allocated; 58.69 MiB free; 4.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=1000_hidden_state_size=1024_embedding_size=50_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 266, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 151, in forward
    out, out_lengths = pad_packed_sequence(out, batch_first=True)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/utils/rnn.py", line 319, in pad_packed_sequence
    return padded_output.index_select(batch_dim, unsorted_indices), lengths[unsorted_indices]
RuntimeError: CUDA out of memory. Tried to allocate 762.00 MiB (GPU 0; 5.93 GiB total capacity; 3.02 GiB already allocated; 646.44 MiB free; 3.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=2000_hidden_state_size=1024_embedding_size=50_no_stem_sr.log results

./logs/max_tokens=125_hidden_state_size=64_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96024
F1 on Train Set: 0.960201793721973
Accuracy on Test Set: 0.78416
F1 on Test Set: 0.7964183309019567

./logs/max_tokens=250_hidden_state_size=64_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.95768
F1 on Train Set: 0.9577138289368505
Accuracy on Test Set: 0.8354133333333333
F1 on Test Set: 0.8380392568489556

./logs/max_tokens=500_hidden_state_size=64_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96312
F1 on Train Set: 0.9631936127744511
Accuracy on Test Set: 0.8502933333333333
F1 on Test Set: 0.8504289444237224

./logs/max_tokens=1000_hidden_state_size=64_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.97112
F1 on Train Set: 0.9710690815835871
Accuracy on Test Set: 0.8485333333333334
F1 on Test Set: 0.8477048477048477

./logs/max_tokens=2000_hidden_state_size=64_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.9666
F1 on Train Set: 0.966451042629274
Accuracy on Test Set: 0.83568
F1 on Test Set: 0.835706286994081

./logs/max_tokens=125_hidden_state_size=128_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.92792
F1 on Train Set: 0.929427430093209
Accuracy on Test Set: 0.7838933333333333
F1 on Test Set: 0.7752385178611048

./logs/max_tokens=250_hidden_state_size=128_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96224
F1 on Train Set: 0.9622097678142513
Accuracy on Test Set: 0.83696
F1 on Test Set: 0.8410048369480418

./logs/max_tokens=500_hidden_state_size=128_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.95888
F1 on Train Set: 0.9586484312148029
Accuracy on Test Set: 0.8413866666666666
F1 on Test Set: 0.8464160297459201

./logs/max_tokens=1000_hidden_state_size=128_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96388
F1 on Train Set: 0.9638727745549109
Accuracy on Test Set: 0.8549866666666667
F1 on Test Set: 0.8547620319427381

./logs/max_tokens=2000_hidden_state_size=128_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.95608
F1 on Train Set: 0.9569107605368496
Accuracy on Test Set: 0.8362666666666667
F1 on Test Set: 0.8384890572390574

./logs/max_tokens=125_hidden_state_size=256_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.95968
F1 on Train Set: 0.9595959595959596
Accuracy on Test Set: 0.80944
F1 on Test Set: 0.8124310987453409

./logs/max_tokens=250_hidden_state_size=256_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96332
F1 on Train Set: 0.9633332000479828
Accuracy on Test Set: 0.84528
F1 on Test Set: 0.8490870311605889

./logs/max_tokens=500_hidden_state_size=256_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96308
F1 on Train Set: 0.963216833379827
Accuracy on Test Set: 0.8514133333333334
F1 on Test Set: 0.8570548999486917

./logs/max_tokens=1000_hidden_state_size=256_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96528
F1 on Train Set: 0.9653437674678591
Accuracy on Test Set: 0.84592
F1 on Test Set: 0.8392409993879028

./logs/max_tokens=2000_hidden_state_size=256_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96808
F1 on Train Set: 0.9680774461956956
Accuracy on Test Set: 0.85648
F1 on Test Set: 0.8535031847133758

./logs/max_tokens=125_hidden_state_size=512_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.94436
F1 on Train Set: 0.9448868814136853
Accuracy on Test Set: 0.8122133333333333
F1 on Test Set: 0.8140480591497228

./logs/max_tokens=250_hidden_state_size=512_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.96824
F1 on Train Set: 0.9683312061263561
Accuracy on Test Set: 0.8476266666666666
F1 on Test Set: 0.8468342893904466

./logs/max_tokens=500_hidden_state_size=512_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.9674
F1 on Train Set: 0.9674559757217586
Accuracy on Test Set: 0.8565866666666667
F1 on Test Set: 0.8537076328817802

./logs/max_tokens=1000_hidden_state_size=512_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.9744
F1 on Train Set: 0.9744286399232859
Accuracy on Test Set: 0.86208
F1 on Test Set: 0.8602615367988761
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 292, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 149, in forward
    out, _ = self.lstm(embeddings)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 695, in forward
    self.num_layers, self.dropout, self.training, self.bidirectional)
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED

./logs/max_tokens=2000_hidden_state_size=512_embedding_size=150_no_stem_sr.log results

./logs/max_tokens=125_hidden_state_size=1024_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.86724
F1 on Train Set: 0.8744847407631509
Accuracy on Test Set: 0.8021333333333334
F1 on Test Set: 0.8133615051816079

./logs/max_tokens=250_hidden_state_size=1024_embedding_size=150_no_stem_sr.log results
Accuracy on Train Set: 0.9258
F1 on Train Set: 0.9270575282135975
Accuracy on Test Set: 0.82784
F1 on Test Set: 0.8344954881050041
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 266, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 151, in forward
    out, out_lengths = pad_packed_sequence(out, batch_first=True)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/utils/rnn.py", line 319, in pad_packed_sequence
    return padded_output.index_select(batch_dim, unsorted_indices), lengths[unsorted_indices]
RuntimeError: CUDA out of memory. Tried to allocate 502.00 MiB (GPU 0; 5.93 GiB total capacity; 3.30 GiB already allocated; 510.56 MiB free; 4.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=500_hidden_state_size=1024_embedding_size=150_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 266, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 151, in forward
    out, out_lengths = pad_packed_sequence(out, batch_first=True)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/utils/rnn.py", line 319, in pad_packed_sequence
    return padded_output.index_select(batch_dim, unsorted_indices), lengths[unsorted_indices]
RuntimeError: CUDA out of memory. Tried to allocate 1002.00 MiB (GPU 0; 5.93 GiB total capacity; 3.50 GiB already allocated; 647.12 MiB free; 4.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=1000_hidden_state_size=1024_embedding_size=150_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 874.00 MiB (GPU 0; 5.93 GiB total capacity; 3.33 GiB already allocated; 442.56 MiB free; 4.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=2000_hidden_state_size=1024_embedding_size=150_no_stem_sr.log results

./logs/max_tokens=125_hidden_state_size=64_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.94424
F1 on Train Set: 0.9444355867346939
Accuracy on Test Set: 0.8199466666666667
F1 on Test Set: 0.821715251373046

./logs/max_tokens=250_hidden_state_size=64_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.965
F1 on Train Set: 0.965212897069932
Accuracy on Test Set: 0.8433066666666666
F1 on Test Set: 0.8454335016835017

./logs/max_tokens=500_hidden_state_size=64_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.94552
F1 on Train Set: 0.9456287425149701
Accuracy on Test Set: 0.8495466666666667
F1 on Test Set: 0.8486831518532425

./logs/max_tokens=1000_hidden_state_size=64_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.97596
F1 on Train Set: 0.9759916909679223
Accuracy on Test Set: 0.8313066666666666
F1 on Test Set: 0.8315671761009639

./logs/max_tokens=2000_hidden_state_size=64_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.95756
F1 on Train Set: 0.957663301544232
Accuracy on Test Set: 0.8458666666666667
F1 on Test Set: 0.8451564509215602

./logs/max_tokens=125_hidden_state_size=128_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.95544
F1 on Train Set: 0.9554720601167158
Accuracy on Test Set: 0.8135466666666666
F1 on Test Set: 0.8128479657387581

./logs/max_tokens=250_hidden_state_size=128_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.9644
F1 on Train Set: 0.9644
Accuracy on Test Set: 0.8314133333333333
F1 on Test Set: 0.832352161230443

./logs/max_tokens=500_hidden_state_size=128_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.96616
F1 on Train Set: 0.9664232417844102
Accuracy on Test Set: 0.8313066666666666
F1 on Test Set: 0.8301197701272893

./logs/max_tokens=1000_hidden_state_size=128_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.96888
F1 on Train Set: 0.9689123311755773
Accuracy on Test Set: 0.8423466666666667
F1 on Test Set: 0.8481922760887427

./logs/max_tokens=2000_hidden_state_size=128_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.95688
F1 on Train Set: 0.9572052401746725
Accuracy on Test Set: 0.8494933333333333
F1 on Test Set: 0.8524058577405859

./logs/max_tokens=125_hidden_state_size=256_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.96544
F1 on Train Set: 0.9656379255488386
Accuracy on Test Set: 0.8216533333333333
F1 on Test Set: 0.8286709703863101

./logs/max_tokens=250_hidden_state_size=256_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.95712
F1 on Train Set: 0.9571165693255461
Accuracy on Test Set: 0.8486933333333333
F1 on Test Set: 0.8465740089773404

./logs/max_tokens=500_hidden_state_size=256_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.97472
F1 on Train Set: 0.9748026473168009
Accuracy on Test Set: 0.8613333333333333
F1 on Test Set: 0.8592464270246859

./logs/max_tokens=1000_hidden_state_size=256_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.97288
F1 on Train Set: 0.972936292511576
Accuracy on Test Set: 0.8632533333333333
F1 on Test Set: 0.8659836922433619

./logs/max_tokens=2000_hidden_state_size=256_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.97996
F1 on Train Set: 0.9799688137219623
Accuracy on Test Set: 0.8612266666666667
F1 on Test Set: 0.8603327965646806

./logs/max_tokens=125_hidden_state_size=512_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.96736
F1 on Train Set: 0.9674796747967481
Accuracy on Test Set: 0.8135466666666666
F1 on Test Set: 0.8059071729957806

./logs/max_tokens=250_hidden_state_size=512_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.96108
F1 on Train Set: 0.9611623358480023
Accuracy on Test Set: 0.8509866666666667
F1 on Test Set: 0.8533487297921478

./logs/max_tokens=500_hidden_state_size=512_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.97348
F1 on Train Set: 0.973512844073349
Accuracy on Test Set: 0.85504
F1 on Test Set: 0.8582898852971846

./logs/max_tokens=1000_hidden_state_size=512_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.97436
F1 on Train Set: 0.9745544043507602
Accuracy on Test Set: 0.84576
F1 on Test Set: 0.8416210295728368
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 266, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 151, in forward
    out, out_lengths = pad_packed_sequence(out, batch_first=True)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/utils/rnn.py", line 319, in pad_packed_sequence
    return padded_output.index_select(batch_dim, unsorted_indices), lengths[unsorted_indices]
RuntimeError: CUDA out of memory. Tried to allocate 894.00 MiB (GPU 0; 5.93 GiB total capacity; 2.74 GiB already allocated; 764.00 MiB free; 3.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=2000_hidden_state_size=512_embedding_size=300_no_stem_sr.log results

./logs/max_tokens=125_hidden_state_size=1024_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.96516
F1 on Train Set: 0.9652281528204718
Accuracy on Test Set: 0.8168
F1 on Test Set: 0.8189914106550035

./logs/max_tokens=250_hidden_state_size=1024_embedding_size=300_no_stem_sr.log results
Accuracy on Train Set: 0.50032
F1 on Train Set: 0.6667378081314694
Accuracy on Test Set: 0.4997333333333333
F1 on Test Set: 0.6662634312958088
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 502.00 MiB (GPU 0; 5.93 GiB total capacity; 3.62 GiB already allocated; 523.94 MiB free; 4.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=500_hidden_state_size=1024_embedding_size=300_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 860.00 MiB (GPU 0; 5.93 GiB total capacity; 3.30 GiB already allocated; 738.44 MiB free; 3.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=1000_hidden_state_size=1024_embedding_size=300_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 266, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 151, in forward
    out, out_lengths = pad_packed_sequence(out, batch_first=True)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/utils/rnn.py", line 319, in pad_packed_sequence
    return padded_output.index_select(batch_dim, unsorted_indices), lengths[unsorted_indices]
RuntimeError: CUDA out of memory. Tried to allocate 744.00 MiB (GPU 0; 5.93 GiB total capacity; 3.67 GiB already allocated; 635.44 MiB free; 4.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=2000_hidden_state_size=1024_embedding_size=300_no_stem_sr.log results

./logs/max_tokens=125_hidden_state_size=64_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.93036
F1 on Train Set: 0.931286261199037
Accuracy on Test Set: 0.8130666666666667
F1 on Test Set: 0.813553912442151

./logs/max_tokens=250_hidden_state_size=64_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.95688
F1 on Train Set: 0.9571098909843241
Accuracy on Test Set: 0.8363733333333333
F1 on Test Set: 0.8383561643835615

./logs/max_tokens=500_hidden_state_size=64_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.95716
F1 on Train Set: 0.9567604667124228
Accuracy on Test Set: 0.8481066666666667
F1 on Test Set: 0.8456703153787797

./logs/max_tokens=1000_hidden_state_size=64_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.98252
F1 on Train Set: 0.98254722632693
Accuracy on Test Set: 0.8411733333333333
F1 on Test Set: 0.8477193700143179

./logs/max_tokens=2000_hidden_state_size=64_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.9698
F1 on Train Set: 0.9697334135097213
Accuracy on Test Set: 0.84912
F1 on Test Set: 0.8491923876539261

./logs/max_tokens=125_hidden_state_size=128_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.94644
F1 on Train Set: 0.9463820926600729
Accuracy on Test Set: 0.8080533333333333
F1 on Test Set: 0.8064741624993278

./logs/max_tokens=250_hidden_state_size=128_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.96872
F1 on Train Set: 0.9688048508058082
Accuracy on Test Set: 0.84272
F1 on Test Set: 0.8460132630149861

./logs/max_tokens=500_hidden_state_size=128_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.94376
F1 on Train Set: 0.9432286198820964
Accuracy on Test Set: 0.8389333333333333
F1 on Test Set: 0.8357803153887983

./logs/max_tokens=1000_hidden_state_size=128_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.97284
F1 on Train Set: 0.9729406607420396
Accuracy on Test Set: 0.8504533333333333
F1 on Test Set: 0.8494900697799249

./logs/max_tokens=2000_hidden_state_size=128_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.97544
F1 on Train Set: 0.9753730145997113
Accuracy on Test Set: 0.8368533333333333
F1 on Test Set: 0.8416092787241755

./logs/max_tokens=125_hidden_state_size=256_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.96356
F1 on Train Set: 0.9636573981728966
Accuracy on Test Set: 0.8002133333333333
F1 on Test Set: 0.794469439262592

./logs/max_tokens=250_hidden_state_size=256_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.97596
F1 on Train Set: 0.9760605457080263
Accuracy on Test Set: 0.84112
F1 on Test Set: 0.8420047732696898

./logs/max_tokens=500_hidden_state_size=256_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.98332
F1 on Train Set: 0.9833273359721721
Accuracy on Test Set: 0.8581866666666667
F1 on Test Set: 0.8564642375168691

./logs/max_tokens=1000_hidden_state_size=256_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.96968
F1 on Train Set: 0.9696314102564102
Accuracy on Test Set: 0.8610133333333333
F1 on Test Set: 0.8610577948389848

./logs/max_tokens=2000_hidden_state_size=256_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.97032
F1 on Train Set: 0.9703033698871368
Accuracy on Test Set: 0.8583466666666667
F1 on Test Set: 0.8573117008703127

./logs/max_tokens=125_hidden_state_size=512_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.91932
F1 on Train Set: 0.9216181556755917
Accuracy on Test Set: 0.8061333333333334
F1 on Test Set: 0.8037362993358891

./logs/max_tokens=250_hidden_state_size=512_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.97916
F1 on Train Set: 0.97919245976277
Accuracy on Test Set: 0.8544
F1 on Test Set: 0.8559214692843571

./logs/max_tokens=500_hidden_state_size=512_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.97232
F1 on Train Set: 0.9722823039333495
Accuracy on Test Set: 0.8649066666666667
F1 on Test Set: 0.8640875677415893

./logs/max_tokens=1000_hidden_state_size=512_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.9778
F1 on Train Set: 0.9778026636803584
Accuracy on Test Set: 0.86416
F1 on Test Set: 0.8640367266321465
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 894.00 MiB (GPU 0; 5.93 GiB total capacity; 3.02 GiB already allocated; 412.19 MiB free; 4.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=2000_hidden_state_size=512_embedding_size=500_no_stem_sr.log results

./logs/max_tokens=125_hidden_state_size=1024_embedding_size=500_no_stem_sr.log results
Accuracy on Train Set: 0.95984
F1 on Train Set: 0.9599617163821981
Accuracy on Test Set: 0.79216
F1 on Test Set: 0.8008177868642985
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 266, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 149, in forward
    out, _ = self.lstm(embeddings)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 695, in forward
    self.num_layers, self.dropout, self.training, self.bidirectional)
RuntimeError: CUDA out of memory. Tried to allocate 1.62 GiB (GPU 0; 5.93 GiB total capacity; 1.43 GiB already allocated; 1.62 GiB free; 2.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=250_hidden_state_size=1024_embedding_size=500_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 502.00 MiB (GPU 0; 5.93 GiB total capacity; 3.65 GiB already allocated; 369.38 MiB free; 4.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=500_hidden_state_size=1024_embedding_size=500_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 816.00 MiB (GPU 0; 5.93 GiB total capacity; 3.51 GiB already allocated; 485.12 MiB free; 4.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=1000_hidden_state_size=1024_embedding_size=500_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 266, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 151, in forward
    out, out_lengths = pad_packed_sequence(out, batch_first=True)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/utils/rnn.py", line 315, in pad_packed_sequence
    sequence.data, sequence.batch_sizes, batch_first, padding_value, max_seq_length)
RuntimeError: CUDA out of memory. Tried to allocate 1.38 GiB (GPU 0; 5.93 GiB total capacity; 3.14 GiB already allocated; 798.75 MiB free; 3.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=2000_hidden_state_size=1024_embedding_size=500_no_stem_sr.log results

./logs/max_tokens=125_hidden_state_size=64_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.94852
F1 on Train Set: 0.9481487450143025
Accuracy on Test Set: 0.81568
F1 on Test Set: 0.8140535887226945

./logs/max_tokens=250_hidden_state_size=64_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97304
F1 on Train Set: 0.9730895152918629
Accuracy on Test Set: 0.8416533333333334
F1 on Test Set: 0.8435474521789534

./logs/max_tokens=500_hidden_state_size=64_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.93048
F1 on Train Set: 0.9303462648284707
Accuracy on Test Set: 0.8382933333333333
F1 on Test Set: 0.8361789496433975

./logs/max_tokens=1000_hidden_state_size=64_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.9184
F1 on Train Set: 0.9176622537939942
Accuracy on Test Set: 0.8334933333333333
F1 on Test Set: 0.8319698600645856

./logs/max_tokens=2000_hidden_state_size=64_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.98304
F1 on Train Set: 0.9830508474576272
Accuracy on Test Set: 0.8379733333333333
F1 on Test Set: 0.8379214682031584

./logs/max_tokens=125_hidden_state_size=128_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97292
F1 on Train Set: 0.9729254149170166
Accuracy on Test Set: 0.81296
F1 on Test Set: 0.8174483368903233

./logs/max_tokens=250_hidden_state_size=128_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.98232
F1 on Train Set: 0.9822945040858836
Accuracy on Test Set: 0.8411733333333333
F1 on Test Set: 0.8391834971379198

./logs/max_tokens=500_hidden_state_size=128_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97156
F1 on Train Set: 0.9715747811138208
Accuracy on Test Set: 0.8455466666666667
F1 on Test Set: 0.8483769633507854

./logs/max_tokens=1000_hidden_state_size=128_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97552
F1 on Train Set: 0.9755258737902902
Accuracy on Test Set: 0.844
F1 on Test Set: 0.8460769352207546

./logs/max_tokens=2000_hidden_state_size=128_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97488
F1 on Train Set: 0.9749341422527341
Accuracy on Test Set: 0.8410133333333333
F1 on Test Set: 0.8423335272650342

./logs/max_tokens=125_hidden_state_size=256_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.95492
F1 on Train Set: 0.9551585564795289
Accuracy on Test Set: 0.8252266666666667
F1 on Test Set: 0.822047244094488

./logs/max_tokens=250_hidden_state_size=256_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97532
F1 on Train Set: 0.9753288816026231
Accuracy on Test Set: 0.828
F1 on Test Set: 0.8229869916021735

./logs/max_tokens=500_hidden_state_size=256_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97868
F1 on Train Set: 0.9787183070473148
Accuracy on Test Set: 0.83936
F1 on Test Set: 0.8414069081718618

./logs/max_tokens=1000_hidden_state_size=256_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.98244
F1 on Train Set: 0.9824687512479533
Accuracy on Test Set: 0.8546666666666667
F1 on Test Set: 0.8533605983963837

./logs/max_tokens=2000_hidden_state_size=256_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97696
F1 on Train Set: 0.9769931298929541
Accuracy on Test Set: 0.8557333333333333
F1 on Test Set: 0.8554171788978566

./logs/max_tokens=125_hidden_state_size=512_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.95884
F1 on Train Set: 0.9589565633600574
Accuracy on Test Set: 0.80208
F1 on Test Set: 0.803702724147051

./logs/max_tokens=250_hidden_state_size=512_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.97392
F1 on Train Set: 0.9738970293858595
Accuracy on Test Set: 0.8493866666666666
F1 on Test Set: 0.8518207576870606
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 266, in fit
    outputs = self.__net(inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "lstm_approach.py", line 149, in forward
    out, _ = self.lstm(embeddings)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 695, in forward
    self.num_layers, self.dropout, self.training, self.bidirectional)
RuntimeError: CUDA out of memory. Tried to allocate 1.08 GiB (GPU 0; 5.93 GiB total capacity; 2.67 GiB already allocated; 1.07 GiB free; 3.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=500_hidden_state_size=512_embedding_size=1000_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED

./logs/max_tokens=1000_hidden_state_size=512_embedding_size=1000_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED

./logs/max_tokens=2000_hidden_state_size=512_embedding_size=1000_no_stem_sr.log results

./logs/max_tokens=125_hidden_state_size=1024_embedding_size=1000_no_stem_sr.log results
Accuracy on Train Set: 0.93244
F1 on Train Set: 0.9327707678223142
Accuracy on Test Set: 0.81856
F1 on Test Set: 0.8147664162038549
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 5.93 GiB total capacity; 3.98 GiB already allocated; 253.38 MiB free; 4.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=250_hidden_state_size=1024_embedding_size=1000_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED

./logs/max_tokens=500_hidden_state_size=1024_embedding_size=1000_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 820.00 MiB (GPU 0; 5.93 GiB total capacity; 3.87 GiB already allocated; 132.88 MiB free; 4.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=1000_hidden_state_size=1024_embedding_size=1000_no_stem_sr.log results
Traceback (most recent call last):
  File "lstm_approach.py", line 453, in <module>
    main()
  File "lstm_approach.py", line 416, in main
    wrapper.fit(train_instances, train_labels, val_instances, val_labels)
  File "lstm_approach.py", line 270, in fit
    loss.backward()
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manosl/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 1022.00 MiB (GPU 0; 5.93 GiB total capacity; 3.73 GiB already allocated; 45.12 MiB free; 4.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

./logs/max_tokens=2000_hidden_state_size=1024_embedding_size=1000_no_stem_sr.log results
